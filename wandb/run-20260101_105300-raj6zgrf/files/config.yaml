_wandb:
    value:
        cli_version: 0.23.1
        e:
            hnt03kqb0394r7xw10t9reo9xstpktlu:
                args:
                    - --dataset=shakespeare_char
                    - --device=cuda
                    - --compile=False
                    - --wandb_log=True
                    - --eval_iters=100
                    - --log_interval=10
                    - --block_size=256
                    - --batch_size=64
                    - --n_layer=4
                    - --n_head=4
                    - --n_embd=256
                    - --max_iters=2000
                codePath: train.py
                codePathLocal: train.py
                cpu_count: 12
                cpu_count_logical: 20
                cudaVersion: "13.1"
                disk:
                    /:
                        total: "1048574947328"
                        used: "606990360576"
                email: zqc199304@gmail.com
                executable: C:\Users\ZHU Qingchuan\AppData\Local\Programs\Python\Python312\python.exe
                git:
                    commit: 3adf61e154c3fe3fca428ad6bc3818b27a3b8291
                    remote: https://github.com/Qingchuan-ZHU/nanoGPT.git
                gpu: NVIDIA GeForce RTX 4070 Ti SUPER
                gpu_count: 1
                gpu_nvidia:
                    - architecture: Ada
                      cudaCores: 8448
                      memoryTotal: "17171480576"
                      name: NVIDIA GeForce RTX 4070 Ti SUPER
                      uuid: GPU-32d224aa-6943-946e-af5a-4a472800f617
                host: Qingchuan-PC
                memory:
                    total: "68448337920"
                os: Windows-11-10.0.26200-SP0
                program: D:\_code\nanoGPT\train.py
                python: CPython 3.12.7
                root: D:\_code\nanoGPT
                startedAt: "2026-01-01T02:53:00.561182Z"
                writerId: hnt03kqb0394r7xw10t9reo9xstpktlu
        m: []
        python_version: 3.12.7
        t:
            "1":
                - 1
            "2":
                - 1
            "3":
                - 13
                - 16
            "4": 3.12.7
            "5": 0.23.1
            "8":
                - 3
            "12": 0.23.1
            "13": windows-amd64
always_save_checkpoint:
    value: true
backend:
    value: nccl
batch_size:
    value: 64
beta1:
    value: 0.9
beta2:
    value: 0.95
bias:
    value: false
block_size:
    value: 256
compile:
    value: false
dataset:
    value: shakespeare_char
decay_lr:
    value: true
device:
    value: cuda
dropout:
    value: 0
dtype:
    value: bfloat16
eval_interval:
    value: 2000
eval_iters:
    value: 100
eval_only:
    value: false
grad_clip:
    value: 1
gradient_accumulation_steps:
    value: 40
init_from:
    value: scratch
learning_rate:
    value: 0.0006
log_interval:
    value: 10
lr_decay_iters:
    value: 600000
max_iters:
    value: 2000
min_lr:
    value: 6e-05
n_embd:
    value: 256
n_head:
    value: 4
n_layer:
    value: 4
out_dir:
    value: out
wandb_log:
    value: true
wandb_project:
    value: owt
wandb_run_name:
    value: gpt2
warmup_iters:
    value: 2000
weight_decay:
    value: 0.1
